---
title: 第三门课-第一周
date: 2018-09-22 20:00:09
tags: 
categories: 
-  深度学习
-  吴恩达课程总结
---

第一周

* 正交化思想

  * 各个变量不相互依赖
  * chain of assumptions in ML：
 training -\> dev -\> test -\> real world
 逐渐向能够拟合real world靠近
  * early stoping不建议使用了，会停止测试集继续拟合，还对开发机有优化，同时影响两个按钮
* 单一数字评估指标
 准确率，召回率两个指标，往往不好判断。所以F1 Score=$\frac{2}{\frac{1}{P} + \frac{1}{R}}$来看整体的情况
* 满足和优化指标

  * 优化指标：是需要不断优化的
  * 满足指标：只需要达到一定的门槛值就行了
* 训练/开发/测试集划分

  * 训练集：用训练集训练不同的模型
  * 开发集：用开发集来评估不同的思路，然后选择一个，不断迭代去改善开发集的性能
  * 用测试集去评估，目的是评估你最终的成本偏差
  * 设立开发集及评估指标，真的就定义了你要瞄准的目标。当然需要在同一分布中设立开发集和测试集
  * 开发集和测试集的数据量大小： 
    * 之前数据量都很小的时候，经常是6/2/2,8/2
    * 现在大数据时代，需要看总体数据量大小，比如10000的开发集，测试集就已经够了
* 什么时候改变开发，测试集指标

  * 第一步为设立目标，第二步为瞄准和射击目标，建议尽快设立一个明确的目标，可以让你的团队高效迭代，改善性能
  * 如果当前指标和数据，和你**真正关心必须做好的事情**关心不大，那就应该更改你的指标或者你的开发测试集，让它们能更好地反映你的算法需要处理好的数据
* Bayes optimal error

  * 贝叶斯错最优错误率一般认为是理论上可能达到的最优错误率，也就是说没有任何一个办法能够超越一定的准确度，通常比人类的表现还要好
  * 现象：ML在你超越人类表现之前，进展都会很快，而超越后就会慢下来了
  * 人类对图像，听写音频，或阅读语言等比较擅长，那么就让其做自己擅长的事情，比如人工标注
* 可避免偏差/方差
 Humans(≈bayes) 1% 7.5%
 Training error 8% 8%
 Dev error 10% 10%
 1%的时候，考虑避免偏差去优化。而7.5%的时候考虑避免方差去优化
* 理解人的表现&超越人的表现

  * (human-\>bayes)通过人类水平的估计做出对贝叶斯错误的估计
  * (train-bayes|human:bias)然后通过比较和贝叶斯错误估计的差别来评估偏差
  * (dev-train:variance)通过dev和train的差距来判断可优化方差的距离
  * 如果已经超过了人类的表现，那么后面的优化会比较缓慢
* Bias/Variance改进方法：

  * Bias： 
    * 规模更大的模型
    * 更优惠的算法，比如momentum,RMSProp,adam
    * 新的神经网络的架构，或者更好的超参数等
    * 改变激活函数，或者隐层数量，单位数据等
    * 尝试其他模型，其他架构，如CNN,RNN等
  * Variance: 
    * 收集更多的数据
    * 正则化，L2,Dropout等
    * 不同神经网络，超参数等

